{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2023-10-17 19:10:32.493373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2023-10-17 19:10:32.493373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2023-10-17 19:10:32.493373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target  \\\n",
       "0           0  I was wondering if anyone out there could enli...       7   \n",
       "1          17  I recently posted an article asking what kind ...       7   \n",
       "2          29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "\n",
       "       title                        date  \n",
       "0  rec.autos  2023-10-17 19:10:32.493373  \n",
       "1  rec.autos  2023-10-17 19:10:32.493373  \n",
       "2  rec.autos  2023-10-17 19:10:32.493373  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../datasets/20_newsgroup.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'title', 'date']\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we do Data Preprocessing.\n",
    "\"\"\"\n",
    "import string, re, nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "regexp = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "def remove_whitespace(text):\n",
    "    return text.strip()\n",
    "def remove_punctuation(text):\n",
    "    punct_str = string.punctuation\n",
    "    punct_str = punct_str.replace(\"'\", \"\") # discarding apostrophe from the string to keep the contractions intact\n",
    "    return text.translate(str.maketrans(\"\", \"\", punct_str))\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "def remove_http(text):\n",
    "    http = \"https?://\\S+|www\\.\\S+\" # matching strings beginning with http (but not just \"http\")\n",
    "    pattern = r\"({})\".format(http) # creating pattern\n",
    "    return re.sub(pattern, \"\", text)\n",
    "# Stopwords\n",
    "stops = stopwords.words(\"english\") # stopwords\n",
    "addstops = [\"among\", \"onto\", \"shall\", \"thrice\", \"thus\", \"twice\", \"unto\", \"us\", \"would\"] # additional stopwords\n",
    "allstops = stops + addstops\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in regexp.tokenize(text) if word not in allstops])\n",
    "stemmer = PorterStemmer()\n",
    "def text_stemmer(text):\n",
    "    text_stem = \" \".join([stemmer.stem(word) for word in regexp.tokenize(text)])\n",
    "    return text_stem\n",
    "def discard_non_alpha(text):\n",
    "    word_list_non_alpha = [word for word in regexp.tokenize(text) if word.isalpha()]\n",
    "    text_non_alpha = \" \".join(word_list_non_alpha)\n",
    "    return text_non_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalizer(text):\n",
    "    text = convert_to_lowercase(text)\n",
    "    text = remove_whitespace(text)\n",
    "    text = re.sub('\\n' , '', text) # converting text to one line\n",
    "    text = re.sub('\\[.*?\\]', '', text) # removing square brackets\n",
    "    text = remove_http(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = discard_non_alpha(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(text_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2), max_features=7500, smooth_idf=True, sublinear_tf=True)\n",
    "vectorizer.fit(df['text'])\n",
    "df_features = vectorizer.transform(df['text'])\n",
    "df_target = df['target']\n",
    "\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(df_features.toarray(), df_target, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(df_features_train, df_target_train)\n",
    "df_target_prediction = nb_model.predict(df_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.35      0.48        88\n",
      "           1       0.56      0.61      0.58       117\n",
      "           2       0.68      0.57      0.62       134\n",
      "           3       0.54      0.62      0.58       122\n",
      "           4       0.66      0.65      0.66       103\n",
      "           5       0.65      0.79      0.72       112\n",
      "           6       0.69      0.71      0.70       107\n",
      "           7       0.77      0.68      0.73       126\n",
      "           8       0.74      0.71      0.72       123\n",
      "           9       0.90      0.73      0.80       129\n",
      "          10       0.64      0.89      0.74       103\n",
      "          11       0.77      0.81      0.79       126\n",
      "          12       0.70      0.62      0.66       117\n",
      "          13       0.89      0.77      0.82       129\n",
      "          14       0.82      0.71      0.76       113\n",
      "          15       0.40      0.96      0.56       108\n",
      "          16       0.64      0.73      0.68        93\n",
      "          17       0.90      0.83      0.87       127\n",
      "          18       0.70      0.44      0.54        71\n",
      "          19       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.68      2220\n",
      "   macro avg       0.67      0.66      0.65      2220\n",
      "weighted avg       0.69      0.68      0.67      2220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(df_target_test, df_target_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b60f5bfde2dc6003c52249e7ba87cb8994d8effec2917dd9467812f9cc41ae70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
