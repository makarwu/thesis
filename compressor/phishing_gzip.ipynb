{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         Email Text  Email Type\n",
       "0           0  re : 6 . 1100 , disc : uniformitarianism , re ...  Safe Email\n",
       "1           1  the other side of * galicismos * * galicismo *...  Safe Email"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../datasets/Phishing_Email.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Email Text      Email Type\n",
       "0  re : 6 . 1100 , disc : uniformitarianism , re ...      Safe Email\n",
       "1  the other side of * galicismos * * galicismo *...      Safe Email\n",
       "2  re : equistar deal tickets are you still avail...      Safe Email\n",
       "3  \\nHello I am your hot lil horny toy.\\n    I am...  Phishing Email\n",
       "4  software at incredibly low prices ( 86 % lower...  Phishing Email"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature          target\n",
       "0  re : 6 . 1100 , disc : uniformitarianism , re ...      Safe Email\n",
       "1  the other side of * galicismos * * galicismo *...      Safe Email\n",
       "2  re : equistar deal tickets are you still avail...      Safe Email\n",
       "3  \\nHello I am your hot lil horny toy.\\n    I am...  Phishing Email\n",
       "4  software at incredibly low prices ( 86 % lower...  Phishing Email"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={\"Email Text\": \"feature\", \"Email Type\": \"target\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we do Data Preprocessing.\n",
    "\"\"\"\n",
    "import string, re, nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "regexp = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "def remove_whitespace(text):\n",
    "    return text.strip()\n",
    "def remove_punctuation(text):\n",
    "    punct_str = string.punctuation\n",
    "    punct_str = punct_str.replace(\"'\", \"\") \n",
    "    return text.translate(str.maketrans(\"\", \"\", punct_str))\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "def remove_http(text):\n",
    "    http = \"https?://\\S+|www\\.\\S+\" \n",
    "    pattern = r\"({})\".format(http) \n",
    "    return re.sub(pattern, \"\", text)\n",
    "# Stopwords\n",
    "stops = stopwords.words(\"english\") \n",
    "addstops = [\"among\", \"onto\", \"shall\", \"thrice\", \"thus\", \"twice\", \"unto\", \"us\", \"would\"] \n",
    "allstops = stops + addstops\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in regexp.tokenize(text) if word not in allstops])\n",
    "stemmer = PorterStemmer()\n",
    "def text_stemmer(text):\n",
    "    text_stem = \" \".join([stemmer.stem(word) for word in regexp.tokenize(text)])\n",
    "    return text_stem\n",
    "def discard_non_alpha(text):\n",
    "    word_list_non_alpha = [word for word in regexp.tokenize(text) if word.isalpha()]\n",
    "    text_non_alpha = \" \".join(word_list_non_alpha)\n",
    "    return text_non_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalizer(text):\n",
    "    text = convert_to_lowercase(text)\n",
    "    text = remove_whitespace(text)\n",
    "    text = re.sub('\\n' , '', text) \n",
    "    text = re.sub('\\[.*?\\]', '', text) \n",
    "    text = remove_http(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = discard_non_alpha(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disc uniformitarianism sex lang dick hudson observations use aughter vocative thoughtprovoking sure fair attribute sons treated like senior relatives one thing normally use brother way aughter hard imagine natural class comprising senior relatives excluding brother another seem differences imagining distinction seems senior relative terms used wider variety contexts e g calling distance get someone attention hence beginning utterance whereas seems natural utterances like yes son hand son ones like son son help although perhaps latter ones completely impossible alexis mr'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature'] = df['feature'].apply(text_normalizer)\n",
    "df['feature'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression Ratio - Train Set: 2.930071188289488\n",
      "Compression Ratio - Test Set: 2.842831972126728\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "# Calculate compression ratio\n",
    "def calculate_compression_ratio(text):\n",
    "    compressed = len(gzip.compress(text.encode()))\n",
    "    original = len(text.encode())\n",
    "    compression_ratio = original / compressed\n",
    "    return compression_ratio\n",
    "\n",
    "# Print compression ratios for train and test sets\n",
    "train_compression_ratio = calculate_compression_ratio(\" \".join(df_train['feature']))\n",
    "test_compression_ratio = calculate_compression_ratio(\" \".join(df_test['feature']))\n",
    "\n",
    "print(\"Compression Ratio - Train Set:\", train_compression_ratio)\n",
    "print(\"Compression Ratio - Test Set:\", test_compression_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N - Number of training examples: 14907\n",
      "N - Number of test examples: 3727\n",
      "C - Number of classes: 2\n",
      "W - Average number of words in each example (Train): 247.98577849332528\n",
      "W - Average number of words in each example (Test): 155.9922189428495\n",
      "L - Average number of characters in each example (Train): 1849.8378614073924\n",
      "L - Average number of characters in each example (Test): 1149.4926214113227\n",
      "V - Vocabulary size: 174180\n"
     ]
    }
   ],
   "source": [
    "#Statistical data about the train and test sets\n",
    "# N - Number of training and test set examples\n",
    "N_train = len(df_train)\n",
    "N_test = len(df_test)\n",
    "\n",
    "# C - Number of classes\n",
    "C = df['target'].nunique()\n",
    "\n",
    "# Calculate average number of words (W) and characters (L) in each example\n",
    "#text is tokenized by spaces\n",
    "train_word_counts = df_train['feature'].apply(lambda x: len(x.split()))\n",
    "test_word_counts = df_test['feature'].apply(lambda x: len(x.split()))\n",
    "train_char_counts = df_train['feature'].apply(lambda x: len(x))\n",
    "test_char_counts = df_test['feature'].apply(lambda x: len(x))\n",
    "W_train = train_word_counts.mean()\n",
    "W_test = test_word_counts.mean()\n",
    "L_train = train_char_counts.mean()\n",
    "L_test = test_char_counts.mean()\n",
    "\n",
    "# V - Vocabulary size\n",
    "#count unique words in the entire dataset\n",
    "all_text = \" \".join(df['feature'])\n",
    "vocabulary = set(all_text.split())\n",
    "V = len(vocabulary)\n",
    "\n",
    "# Print the statistics\n",
    "print(\"N - Number of training examples:\", N_train)\n",
    "print(\"N - Number of test examples:\", N_test)\n",
    "print(\"C - Number of classes:\", C)\n",
    "print(\"W - Average number of words in each example (Train):\", W_train)\n",
    "print(\"W - Average number of words in each example (Test):\", W_test)\n",
    "print(\"L - Average number of characters in each example (Train):\", L_train)\n",
    "print(\"L - Average number of characters in each example (Test):\", L_test)\n",
    "print(\"V - Vocabulary size:\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "#calculate normalized compression distance (NCD)\n",
    "def calculate_ncd(x1, x2):\n",
    "    Cx1 = len(gzip.compress(x1.encode()))\n",
    "    Cx2 = len(gzip.compress(x2.encode()))\n",
    "    x1x2 = \" \".join([x1, x2])\n",
    "    Cx1x2 = len(gzip.compress(x1x2.encode()))\n",
    "    \n",
    "    ncd = (Cx1x2 - min(Cx1, Cx2)) / max(Cx1, Cx2)\n",
    "    return ncd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3727 [00:05<6:02:45,  5.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m distance_from_test_instance \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_train \u001b[38;5;129;01min\u001b[39;00m df_train\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 17\u001b[0m     train_text \u001b[38;5;241m=\u001b[39m \u001b[43mrow_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m     train_label \u001b[38;5;241m=\u001b[39m row_train[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m     c_train_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gzip\u001b[38;5;241m.\u001b[39mcompress(train_text\u001b[38;5;241m.\u001b[39mencode()))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=954'>955</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=956'>957</a>\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=957'>958</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=959'>960</a>\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=960'>961</a>\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=961'>962</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=962'>963</a>\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=1065'>1066</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=1067'>1068</a>\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=1068'>1069</a>\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py?line=1069'>1070</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3627\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mif\u001b[39;00m tolerance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtolerance argument only valid if using pad, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbackfill or nearest lookups\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     )\n\u001b[0;32m-> <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m casted_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_indexer(key)\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3628'>3629</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6304\u001b[0m, in \u001b[0;36mIndex._maybe_cast_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6298'>6299</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6299'>6300</a>\u001b[0m \u001b[39mIf we have a float key and are not a floating index, then try to cast\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6300'>6301</a>\u001b[0m \u001b[39mto an int if equivalent.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6301'>6302</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6302'>6303</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_floating():\n\u001b[0;32m-> <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6303'>6304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m com\u001b[39m.\u001b[39;49mcast_scalar_indexer(key)\n\u001b[1;32m   <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6304'>6305</a>\u001b[0m \u001b[39mreturn\u001b[39;00m key\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:175\u001b[0m, in \u001b[0;36mcast_scalar_indexer\u001b[0;34m(val, warn_float)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=160'>161</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=161'>162</a>\u001b[0m \u001b[39mTo avoid numpy DeprecationWarnings, cast float to integer where valid.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=162'>163</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=171'>172</a>\u001b[0m \u001b[39moutval : scalar\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=172'>173</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=173'>174</a>\u001b[0m \u001b[39m# assumes lib.is_scalar(val)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=174'>175</a>\u001b[0m \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39;49mis_float(val) \u001b[39mand\u001b[39;00m val\u001b[39m.\u001b[39mis_integer():\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=175'>176</a>\u001b[0m     \u001b[39mif\u001b[39;00m warn_float:\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=176'>177</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=177'>178</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIndexing with a float is deprecated, and will raise an IndexError \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=178'>179</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39min pandas 2.0. You can manually convert to an integer key instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=179'>180</a>\u001b[0m             \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=180'>181</a>\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    <a href='file:///Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py?line=181'>182</a>\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#normale Gzip-Klassifikationsvariante\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "k = 2\n",
    "\n",
    "predicted_classes = []\n",
    "\n",
    "for row_test in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
    "    test_text = row_test[1][\"feature\"]\n",
    "    test_label = row_test[1][\"target\"]\n",
    "    c_test_text = len(gzip.compress(test_text.encode()))\n",
    "    distance_from_test_instance = []\n",
    "    \n",
    "    for row_train in df_train.iterrows():\n",
    "        train_text = row_train[1][\"feature\"]\n",
    "        train_label = row_train[1][\"target\"]\n",
    "        c_train_text = len(gzip.compress(train_text.encode()))\n",
    "        \n",
    "        train_plus_test = \" \".join([test_text, train_text])\n",
    "        c_train_plus_test = len(gzip.compress(train_plus_test.encode()))\n",
    "        \n",
    "        ncd = ( (c_train_plus_test - min(c_train_text, c_test_text))\n",
    "                / max(c_test_text, c_train_text) )\n",
    "        distance_from_test_instance.append(ncd)\n",
    "        \n",
    "    sorted_idx = np.argsort(np.array(distance_from_test_instance))\n",
    "    \n",
    "    top_k_class = list(df_train.iloc[sorted_idx[:k]][\"target\"].values)\n",
    "    predicted_class = max(set(top_k_class), key=top_k_class.count)\n",
    "    #top_k_class = df_train.iloc[sorted_idx[:k]][\"target\"].values\n",
    "    #predicted_class = np.argmax(np.bincount(top_k_class))\n",
    "    \n",
    "    predicted_classes.append(predicted_class)\n",
    "     \n",
    "print(\"Accuracy:\", np.mean(np.array(predicted_classes) == df_test[\"target\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#with Tie-breaking fix (MORE ACCURACY)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "k = 2\n",
    "\n",
    "predicted_classes = []\n",
    "\n",
    "for row_test in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
    "    test_text = row_test[1][\"feature\"]\n",
    "    test_label = row_test[1][\"target\"]\n",
    "    c_test_text = len(gzip.compress(test_text.encode()))\n",
    "    distance_from_test_instance = []\n",
    "    \n",
    "    for row_train in df_train.iterrows():\n",
    "        train_text = row_train[1][\"feature\"]\n",
    "        train_label = row_train[1][\"target\"]\n",
    "        c_train_text = len(gzip.compress(train_text.encode()))\n",
    "        \n",
    "        train_plus_test = \" \".join([test_text, train_text])\n",
    "        c_train_plus_test = len(gzip.compress(train_plus_test.encode()))\n",
    "        \n",
    "        ncd = ( (c_train_plus_test - min(c_train_text, c_test_text))\n",
    "                / max(c_test_text, c_train_text) )\n",
    "        distance_from_test_instance.append(ncd)\n",
    "        \n",
    "    sorted_idx = np.argsort(np.array(distance_from_test_instance))\n",
    "    top_k_class = np.array(df_train[\"target\"])[sorted_idx[:k]]\n",
    "    predicted_class = Counter(top_k_class).most_common()[0][0]\n",
    "    \n",
    "    predicted_classes.append(predicted_class)\n",
    "        \n",
    "print(\"Accuracy:\", np.mean(np.array(predicted_classes) == df_test[\"target\"].values))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#true labels for the test set\n",
    "true_labels = df_test['target']\n",
    "\n",
    "# Compute the classification report\n",
    "classification_report_output = classification_report(true_labels, predicted_classes)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report_output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b60f5bfde2dc6003c52249e7ba87cb8994d8effec2917dd9467812f9cc41ae70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
