{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from datasets import load_dataset\\nimport pandas as pd\\n\\nscicite = load_dataset('sst2')\\n\\n# Convert to a pandas DataFrame\\ndf = pd.DataFrame({\\n    'text': scicite['train']['sentence'],\\n    'label': scicite['train']['label'],\\n})\\n\\n# Save to CSV\\ndf.to_csv('sst2.csv', index=False)\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "scicite = load_dataset('sst2')\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': scicite['train']['sentence'],\n",
    "    'label': scicite['train']['label'],\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('sst2.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1\n",
       "3  remains utterly satisfied to remain the same t...      0\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/sst2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67349, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we do Data Preprocessing.\n",
    "\"\"\"\n",
    "import string, re, nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "regexp = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "def remove_whitespace(text):\n",
    "    return text.strip()\n",
    "def remove_punctuation(text):\n",
    "    punct_str = string.punctuation\n",
    "    punct_str = punct_str.replace(\"'\", \"\") # discarding apostrophe from the string to keep the contractions intact\n",
    "    return text.translate(str.maketrans(\"\", \"\", punct_str))\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "def remove_http(text):\n",
    "    http = \"https?://\\S+|www\\.\\S+\" # matching strings beginning with http (but not just \"http\")\n",
    "    pattern = r\"({})\".format(http) # creating pattern\n",
    "    return re.sub(pattern, \"\", text)\n",
    "# Stopwords\n",
    "stops = stopwords.words(\"english\") # stopwords\n",
    "addstops = [\"among\", \"onto\", \"shall\", \"thrice\", \"thus\", \"twice\", \"unto\", \"us\", \"would\"] # additional stopwords\n",
    "allstops = stops + addstops\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in regexp.tokenize(text) if word not in allstops])\n",
    "stemmer = PorterStemmer()\n",
    "def text_stemmer(text):\n",
    "    text_stem = \" \".join([stemmer.stem(word) for word in regexp.tokenize(text)])\n",
    "    return text_stem\n",
    "def discard_non_alpha(text):\n",
    "    word_list_non_alpha = [word for word in regexp.tokenize(text) if word.isalpha()]\n",
    "    text_non_alpha = \" \".join(word_list_non_alpha)\n",
    "    return text_non_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalizer(text):\n",
    "    text = convert_to_lowercase(text)\n",
    "    text = remove_whitespace(text)\n",
    "    text = re.sub('\\n' , '', text) # converting text to one line\n",
    "    text = re.sub('\\[.*?\\]', '', text) # removing square brackets\n",
    "    text = remove_http(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = discard_non_alpha(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(text_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2), max_features=60000, smooth_idf=True, sublinear_tf=True)\n",
    "df_feature = vectorizer.fit_transform(df['text'])\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(df_feature, df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(df_features_train, df_target_train)\n",
    "target_prediction = dt_model.predict(df_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      5909\n",
      "           1       0.91      0.92      0.91      7561\n",
      "\n",
      "    accuracy                           0.90     13470\n",
      "   macro avg       0.90      0.90      0.90     13470\n",
      "weighted avg       0.90      0.90      0.90     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(df_target_test, target_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b60f5bfde2dc6003c52249e7ba87cb8994d8effec2917dd9467812f9cc41ae70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
